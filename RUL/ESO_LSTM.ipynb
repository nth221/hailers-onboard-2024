{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1953,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1954,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# gpu\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    mps_device = torch.device(device)\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "    print(device)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1955,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10fe08af0>"
      ]
     },
     "execution_count": 1955,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random seed to make results deterministic and reproducible\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1956,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "\n",
    "seq_length = 10\n",
    "data_dim = 200 # Exclude label\n",
    "hidden_dim = 30\n",
    "output_dim = 1\n",
    "learning_rate = 0.015\n",
    "iterations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1957,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.min(data, 0)  ->  열(column)별 최소값\n",
    "# np.max(data, 0)  ->  열(column)별 최대값\n",
    "# scaling function for input data\n",
    "def minmax_scaler(data):\n",
    "    # numerator: 원본 데이터 - 최소값 = 데이터를 0 기준으로 이동\n",
    "    numerator = data - np.min(data, axis=0)\n",
    "    # denominator: 최대값과 최소값의 차: 데이터의 범위\n",
    "    denominator = np.max(data, axis=0) - np.min(data, axis=0)\n",
    "\n",
    "    # 데이터의 값을 0과 1 사이로 스케일링\n",
    "    # 1e-7: ZeroDivisionError 방지\n",
    "    return numerator / (denominator + 1e-7), np.min(data, axis=0), np.max(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1958,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse scaling function\n",
    "def inverse_minmax_scaler(data, min_val, max_val):\n",
    "    return data * (max_val - min_val + 1e-7) + min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1959,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset to input\n",
    "# 시계열 데이터를 입력으로 받아 학습에 사용할 데이터셋을 생성\n",
    "def build_dataset(time_series, seq_length):\n",
    "\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "\n",
    "    # 반복문 0~(데이터 길이 - 시퀀스 길이)\n",
    "    for i in range(0, len(time_series) - seq_length):\n",
    "\n",
    "        # row: i부터 시퀀스 길이(i+시퀀스 길이 직전) | column: 전부(label 행 포함)\n",
    "        #_x = time_series[i:i + seq_length, :] # Include the close price column\n",
    "        _x = time_series[i:i + seq_length, :-1] # Exclude the close price column\n",
    "\n",
    "        # row: i+시퀀스 길이 열(1개 열) | column: 마지막 행 (label, 종가)\n",
    "        _y = time_series[i + seq_length, [-1]]  # Next close price\n",
    "\n",
    "        # print(_x, \"->\", _y) # 시각화\n",
    "\n",
    "        dataX.append(_x) # input data set에 추가\n",
    "        dataY.append(_y) # label set에 추가\n",
    "\n",
    "    # numpy 배열로 리턴\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1960,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset to input\n",
    "# 시계열 데이터를 입력으로 받아 학습에 사용할 데이터셋을 생성\n",
    "def build_dataset_test(time_series, seq_length):\n",
    "\n",
    "    dataX = []\n",
    "\n",
    "    # 반복문 0~(데이터 길이 - 시퀀스 길이)\n",
    "    for i in range(0, len(time_series) - seq_length):\n",
    "\n",
    "        # row: i부터 시퀀스 길이(i+시퀀스 길이 직전) | column: 전부(label 행 포함)\n",
    "        #_x = time_series[i:i + seq_length, :] # Include the close price column\n",
    "        _x = time_series[i:i + seq_length, :] # Exclude the close price column\n",
    "\n",
    "        # print(_x, \"->  ?\") # 시각화\n",
    "\n",
    "        dataX.append(_x) # input data set에 추가\n",
    "\n",
    "    # numpy 배열로 리턴\n",
    "    return np.array(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1961,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 채우기 함수 (벡터화된 방식)\n",
    "def fill_missing_values_vectorized(data):\n",
    "    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    columns_to_process = [col for col in numeric_columns if col not in ['id']]\n",
    "    \n",
    "    data = data.copy()  # 원본 데이터 수정 방지\n",
    "\n",
    "    even_id_indices = data.index[data['id'] % 2 == 0]\n",
    "    \n",
    "    for col in columns_to_process:\n",
    "        col_data = data[col].values\n",
    "        for i in even_id_indices:\n",
    "            if np.isnan(col_data[i]):\n",
    "                if i == 0:\n",
    "                    col_data[i] = col_data[i + 1]\n",
    "                elif i == len(col_data) - 1:\n",
    "                    col_data[i] = col_data[i - 1]\n",
    "                else:\n",
    "                    prev_val = col_data[i - 1]\n",
    "                    next_val = col_data[i + 1]\n",
    "                    if not np.isnan(prev_val) and not np.isnan(next_val):\n",
    "                        col_data[i] = (prev_val + next_val) / 2\n",
    "                    elif not np.isnan(prev_val):\n",
    "                        col_data[i] = prev_val\n",
    "                    elif not np.isnan(next_val):\n",
    "                        col_data[i] = next_val\n",
    "        data[col] = col_data\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1962,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39457, 294)\n",
      "(9888, 293)\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "train_set = pd.read_csv(\"./data/train_data.csv\")\n",
    "print(train_set.shape)\n",
    "# print(train_set.head())\n",
    "\n",
    "# load test data\n",
    "test_set = pd.read_csv(\"./data/test_data.csv\")\n",
    "print(test_set.shape)\n",
    "# print(test_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1963,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39457, 204)\n",
      "(9888, 203)\n"
     ]
    }
   ],
   "source": [
    "# 불필요한 열 제거\n",
    "# column에 모든 value가 같으면 해당 column 제거\n",
    "\n",
    "train_set = train_set.loc[:, train_set.nunique() != 1]\n",
    "print(train_set.shape)\n",
    "\n",
    "test_set = test_set.loc[:, test_set.nunique() != 1]\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1964,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39457, 204)\n",
      "(9888, 203)\n"
     ]
    }
   ],
   "source": [
    "# 비어있는 셀에 같은 column 앞,뒤 셀의 평균을 채워넣기\n",
    "\n",
    "filled_train_set = fill_missing_values_vectorized(train_set)\n",
    "print(filled_train_set.shape)\n",
    "# print(type(filled_train_set))\n",
    "\n",
    "filled_test_set = fill_missing_values_vectorized(test_set)\n",
    "print(filled_test_set.shape)\n",
    "# print(type(filled_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1965,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39457, 202)\n",
      "(9888, 201)\n"
     ]
    }
   ],
   "source": [
    "# id, time column 버리기\n",
    "\n",
    "PP_train_data = filled_train_set.iloc[:,2:]\n",
    "print(PP_train_data.shape)\n",
    "# print(type(filled_train_set))\n",
    "\n",
    "PP_test_data = filled_test_set.iloc[:,2:]\n",
    "print(PP_test_data.shape)\n",
    "# print(type(PP_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1966,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39457, 202)\n"
     ]
    }
   ],
   "source": [
    "# PP_train_data 만 !!!\n",
    "# 첫 번째 열(battery_output)을 마지막(y_data 위치)으로 이동\n",
    "cols = PP_train_data.columns.tolist()\n",
    "cols.append(cols.pop(0))\n",
    "PP_train_data = PP_train_data[cols]\n",
    "print(PP_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1967,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39457, 201)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(9888, 200)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# J번째 column 버리기 (값이 유실된 cell 다수)\n",
    "PP_train_data = PP_train_data.drop(PP_train_data.columns[9], axis=1)\n",
    "PP_test_data = PP_test_data.drop(PP_test_data.columns[9], axis=1)\n",
    "\n",
    "# 아직도 빈 곳을 column의 평균으로 채우기\n",
    "PP_train_data = PP_train_data.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "PP_test_data = PP_test_data.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "\n",
    "# column name 담긴 row 앞에 '#' 추가\n",
    "PP_train_data = PP_train_data.rename(columns={'East_Midlands_price': '#East_Midlands_price'})\n",
    "PP_test_data = PP_test_data.rename(columns={'East_Midlands_price': '#East_Midlands_price'})\n",
    "\n",
    "print(PP_train_data.shape)\n",
    "print(type(PP_train_data))\n",
    "print(PP_test_data.shape)\n",
    "print(type(PP_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1968,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9898, 200)\n"
     ]
    }
   ],
   "source": [
    "# train_data의 마지막 seq_length 만큼의 행을 선택\n",
    "last_rows = PP_train_data.iloc[-seq_length:].copy()\n",
    "\n",
    "# test_data의 0번째 행 앞에 last_82_rows를 추가\n",
    "# 컬럼 수가 다르므로 일치시키기 위해 마지막 열을 제거합니다.\n",
    "last_rows_trimmed = last_rows.iloc[:, :-1]\n",
    "\n",
    "# test_data와 동일한 컬럼 수로 맞춘 데이터프레임을 새로 생성\n",
    "PP_test_data = pd.concat([last_rows_trimmed, PP_test_data], ignore_index=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(PP_test_data.shape)\n",
    "# print(PP_test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1969,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39457, 201)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(9898, 200)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(PP_train_data.shape)\n",
    "print(type(PP_train_data))\n",
    "print(PP_test_data.shape)\n",
    "print(type(PP_test_data))\n",
    "\n",
    "# 전처리 된 data set 추출 \n",
    "PP_train_data.to_csv('./PP_data/PP_train_data.csv', index=False)\n",
    "PP_test_data.to_csv('./PP_data/PP_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1970,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39457, 201)\n",
      "(9898, 200)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_set = np.loadtxt(\"./PP_data/PP_train_data.csv\", delimiter=\",\")\n",
    "test_set = np.loadtxt(\"./PP_data/PP_test_data.csv\", delimiter=\",\")\n",
    "\n",
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1971,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39447, 10, 200)\n",
      "(39447, 1)\n",
      "\n",
      "(9888, 10, 200)\n"
     ]
    }
   ],
   "source": [
    "# make train-test dataset to input\n",
    "trainX, trainY = build_dataset(train_set, seq_length)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "testX = build_dataset_test(test_set, seq_length)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1972,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39447, 10, 200)\n",
      "(39447, 1)\n",
      "\n",
      "(9888, 10, 200)\n"
     ]
    }
   ],
   "source": [
    "# scaling data (정규화)\n",
    "trainX, _, _ = minmax_scaler(trainX)\n",
    "trainY, trainY_min, trainY_max = minmax_scaler(trainY)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "testX, _, _ = minmax_scaler(testX)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1973,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39447, 10, 200])\n",
      "torch.Size([39447, 1])\n",
      "\n",
      "torch.Size([9888, 10, 200])\n"
     ]
    }
   ],
   "source": [
    "# convert to tensor\n",
    "# MSE loss 사용할거라 Y data가 FloatTensor 타입이어도 괜찮음.\n",
    "# 애초에 주식 종가를 LongTendor 타입으로 변환해서 label로 쓰기에는 무리.\n",
    "trainX_tensor = torch.FloatTensor(trainX).to(device)\n",
    "trainY_tensor = torch.FloatTensor(trainY).to(device)\n",
    "print(trainX_tensor.shape)\n",
    "print(trainY_tensor.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "testX_tensor = torch.FloatTensor(testX).to(device)\n",
    "print(testX_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1974,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(trainX_tensor, trainY_tensor)\n",
    "\n",
    "batch_size = 1024\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1975,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module): # RNN 모델\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
    "        super(Net, self).__init__()\n",
    "        # LSTM 사용\n",
    "        self.rnn = torch.nn.LSTM(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x[:, -1])\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(data_dim, hidden_dim, output_dim, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1976,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss & optimizer setting\n",
    "criterion = torch.nn.MSELoss() # MSE 사용\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1977,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6184326410293579\n",
      "1 3.7209739685058594\n",
      "1 0.7355270385742188\n",
      "1 0.005181744694709778\n",
      "1 0.15929530560970306\n",
      "1 0.3059770464897156\n",
      "1 0.3721890151500702\n",
      "1 0.3627510666847229\n",
      "1 0.32862725853919983\n",
      "1 0.27913516759872437\n",
      "1 0.22902272641658783\n",
      "1 0.1796029806137085\n",
      "1 0.13378500938415527\n",
      "1 0.09590889513492584\n",
      "1 0.0657758042216301\n",
      "1 0.04218364134430885\n",
      "1 0.02456279657781124\n",
      "1 0.01230937521904707\n",
      "1 0.005033011548221111\n",
      "1 0.001796352444216609\n",
      "1 0.001948365243151784\n",
      "1 0.005659844726324081\n",
      "1 0.011048361659049988\n",
      "1 0.015434244647622108\n",
      "1 0.019203243777155876\n",
      "1 0.02184596285223961\n",
      "1 0.021595265716314316\n",
      "1 0.020551113411784172\n",
      "1 0.016501668840646744\n",
      "1 0.012960178777575493\n",
      "1 0.008890136145055294\n",
      "1 0.005657113157212734\n",
      "1 0.0032882920932024717\n",
      "1 0.001906386110931635\n",
      "1 0.0015129207167774439\n",
      "1 0.0017003670800477266\n",
      "1 0.0023788968101143837\n",
      "1 0.0024787981528788805\n",
      "1 0.0033324642572551966\n",
      "2 0.003783704712986946\n",
      "2 0.004698282107710838\n",
      "2 0.004690882749855518\n",
      "2 0.0047365897335112095\n",
      "2 0.004140859004110098\n",
      "2 0.0036949568893760443\n",
      "2 0.0032996637746691704\n",
      "2 0.0029641774017363787\n",
      "2 0.0021426482126116753\n",
      "2 0.0018670487916097045\n",
      "2 0.001692265272140503\n",
      "2 0.0010541792726144195\n",
      "2 0.001380515517666936\n",
      "2 0.0014062091941013932\n",
      "2 0.001169047667644918\n",
      "2 0.0015801433473825455\n",
      "2 0.001631706953048706\n",
      "2 0.0018617103341966867\n",
      "2 0.0017997532850131392\n",
      "2 0.0020040825475007296\n",
      "2 0.0018072865204885602\n",
      "2 0.0014928111340850592\n",
      "2 0.0013887800741940737\n",
      "2 0.0015128583181649446\n",
      "2 0.00170626281760633\n",
      "2 0.001297738403081894\n",
      "2 0.0010279524140059948\n",
      "2 0.001059002592228353\n",
      "2 0.001251573208719492\n",
      "2 0.0010679371189326048\n",
      "2 0.0011353145819157362\n",
      "2 0.0011051105102524161\n",
      "2 0.0012949941447004676\n",
      "2 0.0016049363184720278\n",
      "2 0.001030824496410787\n",
      "2 0.0013631824404001236\n",
      "2 0.0012878486886620522\n",
      "2 0.0011741929920390248\n",
      "2 0.0013172250473871827\n",
      "3 0.000954547431319952\n",
      "3 0.0009681115625426173\n",
      "3 0.0010241770651191473\n",
      "3 0.0010752864181995392\n",
      "3 0.0008830597507767379\n",
      "3 0.0010541703086346388\n",
      "3 0.0008669545059092343\n",
      "3 0.0009699430665932596\n",
      "3 0.0016720875864848495\n",
      "3 0.0012386671733111143\n",
      "3 0.001057154848240316\n",
      "3 0.0009603323414921761\n",
      "3 0.0011090660700574517\n",
      "3 0.0009683918906375766\n",
      "3 0.0016024147626012564\n",
      "3 0.0011607228079810739\n",
      "3 0.0009347231825813651\n",
      "3 0.0009770398028194904\n",
      "3 0.0009009448694996536\n",
      "3 0.0011849704897031188\n",
      "3 0.0011407309211790562\n",
      "3 0.001557819894514978\n",
      "3 0.0009420505375601351\n",
      "3 0.0008837631321512163\n",
      "3 0.0008595788385719061\n",
      "3 0.0010383104672655463\n",
      "3 0.001169477473013103\n",
      "3 0.0015845082234591246\n",
      "3 0.0010822599288076162\n",
      "3 0.0011535454541444778\n",
      "3 0.0012732326285913587\n",
      "3 0.0012197833275422454\n",
      "3 0.000995273469015956\n",
      "3 0.0011066291481256485\n",
      "3 0.0007457102183252573\n",
      "3 0.0014510401524603367\n",
      "3 0.0010503815719857812\n",
      "3 0.0009988360106945038\n",
      "3 0.0007677504909224808\n",
      "4 0.001572310458868742\n",
      "4 0.0009238455677405\n",
      "4 0.0014606970362365246\n",
      "4 0.0012404841836541891\n",
      "4 0.0012959237210452557\n",
      "4 0.0009529604576528072\n",
      "4 0.0009046914638020098\n",
      "4 0.000992366811260581\n",
      "4 0.0010253536747768521\n",
      "4 0.0008518984541296959\n",
      "4 0.001267201267182827\n",
      "4 0.000824364775326103\n",
      "4 0.0012952309334650636\n",
      "4 0.0013948095729574561\n",
      "4 0.0008463002159260213\n",
      "4 0.0011056793155148625\n",
      "4 0.0012875236570835114\n",
      "4 0.0009690336300991476\n",
      "4 0.0010293909581378102\n",
      "4 0.0010983498068526387\n",
      "4 0.0009777868399396539\n",
      "4 0.0009024104801937938\n",
      "4 0.0011687492951750755\n",
      "4 0.000876371341291815\n",
      "4 0.0007617819355800748\n",
      "4 0.0012543090851977468\n",
      "4 0.0008976328535936773\n",
      "4 0.001152395736426115\n",
      "4 0.0008650068193674088\n",
      "4 0.0009340372635051608\n",
      "4 0.0007975687622092664\n",
      "4 0.0012784033315256238\n",
      "4 0.000991392065770924\n",
      "4 0.0010989897418767214\n",
      "4 0.0011526035377755761\n",
      "4 0.0007677144021727145\n",
      "4 0.000785715295933187\n",
      "4 0.0008856417844071984\n",
      "4 0.000848822935950011\n",
      "5 0.0010914106387645006\n",
      "5 0.0009738641674630344\n",
      "5 0.0011254475684836507\n",
      "5 0.001041981391608715\n",
      "5 0.0008823854732327163\n",
      "5 0.0012169359251856804\n",
      "5 0.0009773733327165246\n",
      "5 0.0008921929402276874\n",
      "5 0.0008946326561272144\n",
      "5 0.0009141763439401984\n",
      "5 0.000961725483648479\n",
      "5 0.0007615074282512069\n",
      "5 0.0014464033301919699\n",
      "5 0.0015767873264849186\n",
      "5 0.0008448435692116618\n",
      "5 0.0007675185333937407\n",
      "5 0.0007614500354975462\n",
      "5 0.0010371991666033864\n",
      "5 0.001029746956191957\n",
      "5 0.0012006174074485898\n",
      "5 0.0009527147049084306\n",
      "5 0.0011296584270894527\n",
      "5 0.0009481317829340696\n",
      "5 0.0012202347861602902\n",
      "5 0.0013530601281672716\n",
      "5 0.000776805798523128\n",
      "5 0.0010061212815344334\n",
      "5 0.0008171292720362544\n",
      "5 0.0009560986654832959\n",
      "5 0.000809644116088748\n",
      "5 0.0008395843324251473\n",
      "5 0.0009533611009828746\n",
      "5 0.0008545088348910213\n",
      "5 0.0015963686164468527\n",
      "5 0.0010251585626974702\n",
      "5 0.0011266327928751707\n",
      "5 0.0010531179141253233\n",
      "5 0.0009346689330413938\n",
      "5 0.0007182408589869738\n",
      "6 0.001158150495029986\n",
      "6 0.0012309629237279296\n",
      "6 0.0013935359893366694\n",
      "6 0.0010042502544820309\n",
      "6 0.0010739160934463143\n",
      "6 0.0008024649578146636\n",
      "6 0.0012360872933641076\n",
      "6 0.0007548874127678573\n",
      "6 0.00142288813367486\n",
      "6 0.0009070880478248\n",
      "6 0.001158027327619493\n",
      "6 0.000959735712967813\n",
      "6 0.001008825609460473\n",
      "6 0.0008648994844406843\n",
      "6 0.0008443307015113533\n",
      "6 0.0011077846866101027\n",
      "6 0.0009612009744159877\n",
      "6 0.0011025374988093972\n",
      "6 0.0012486947234719992\n",
      "6 0.0010161488316953182\n",
      "6 0.0008954150252975523\n",
      "6 0.0010369648225605488\n",
      "6 0.0011550773633643985\n",
      "6 0.001111732330173254\n",
      "6 0.0007559249643236399\n",
      "6 0.000829809345304966\n",
      "6 0.0008207049104385078\n",
      "6 0.0008228428196161985\n",
      "6 0.0009820141131058335\n",
      "6 0.0007421148475259542\n",
      "6 0.0012396862730383873\n",
      "6 0.0008609607466496527\n",
      "6 0.00081545120337978\n",
      "6 0.0010024922667071223\n",
      "6 0.0008533307118341327\n",
      "6 0.0008495538495481014\n",
      "6 0.000729937048163265\n",
      "6 0.0011014770716428757\n",
      "6 0.0007124131661839783\n",
      "7 0.0008045310387387872\n",
      "7 0.000991380074992776\n",
      "7 0.001096111722290516\n",
      "7 0.0012374160578474402\n",
      "7 0.000996739137917757\n",
      "7 0.0013805507915094495\n",
      "7 0.0010877054883167148\n",
      "7 0.0009252519230358303\n",
      "7 0.0007340587326325476\n",
      "7 0.0012134333373978734\n",
      "7 0.0009564956417307258\n",
      "7 0.0009819373954087496\n",
      "7 0.0008576730615459383\n",
      "7 0.0008725582738406956\n",
      "7 0.0008488607709296048\n",
      "7 0.000961905054282397\n",
      "7 0.000733687833417207\n",
      "7 0.0008310233824886382\n",
      "7 0.0013295679818838835\n",
      "7 0.0011603805469349027\n",
      "7 0.0006376588135026395\n",
      "7 0.0007873534341342747\n",
      "7 0.0009539401507936418\n",
      "7 0.0009036625851877034\n",
      "7 0.001210217596963048\n",
      "7 0.001269451342523098\n",
      "7 0.0009542922489345074\n",
      "7 0.0009627086692489684\n",
      "7 0.0009979484602808952\n",
      "7 0.0007759472355246544\n",
      "7 0.0008662624750286341\n",
      "7 0.0009120040340349078\n",
      "7 0.0010881085181608796\n",
      "7 0.0007388980593532324\n",
      "7 0.0011394370812922716\n",
      "7 0.001264744671061635\n",
      "7 0.0007702038274146616\n",
      "7 0.0007252598879858851\n",
      "7 0.0011603118618950248\n",
      "8 0.0007563339895568788\n",
      "8 0.0008882401743903756\n",
      "8 0.0010356061393395066\n",
      "8 0.0010601617395877838\n",
      "8 0.0010299220448359847\n",
      "8 0.0009713878389447927\n",
      "8 0.0009769327007234097\n",
      "8 0.0008786211255937815\n",
      "8 0.00114400964230299\n",
      "8 0.0010043031070381403\n",
      "8 0.0008371220901608467\n",
      "8 0.0011576061369851232\n",
      "8 0.0006928358925506473\n",
      "8 0.0006952297408133745\n",
      "8 0.0010427278466522694\n",
      "8 0.0007381413015536964\n",
      "8 0.001042523654177785\n",
      "8 0.0010605545248836279\n",
      "8 0.0009229712886735797\n",
      "8 0.0007553089526481926\n",
      "8 0.0008001574315130711\n",
      "8 0.0007122419192455709\n",
      "8 0.0011788145639002323\n",
      "8 0.0008128922199830413\n",
      "8 0.0007422097260132432\n",
      "8 0.000963783182669431\n",
      "8 0.0009540064493194222\n",
      "8 0.001511402428150177\n",
      "8 0.0009076233254745603\n",
      "8 0.001217271201312542\n",
      "8 0.0011295925360172987\n",
      "8 0.0006716749048791826\n",
      "8 0.0008576835971325636\n",
      "8 0.0009972208645194769\n",
      "8 0.000937342643737793\n",
      "8 0.0009397169342264533\n",
      "8 0.0010639516403898597\n",
      "8 0.0014033032348379493\n",
      "8 0.0011215221602469683\n",
      "9 0.0012104857014492154\n",
      "9 0.0010295253014191985\n",
      "9 0.0008342087967321277\n",
      "9 0.0010333876125514507\n",
      "9 0.0009035419789142907\n",
      "9 0.0010864288778975606\n",
      "9 0.0012193566653877497\n",
      "9 0.0010620513930916786\n",
      "9 0.0006611372227780521\n",
      "9 0.0008585827308706939\n",
      "9 0.0008257061126641929\n",
      "9 0.0008657513535581529\n",
      "9 0.0007941502844914794\n",
      "9 0.0009300382807850838\n",
      "9 0.0010533162858337164\n",
      "9 0.0007341196178458631\n",
      "9 0.0009753180202096701\n",
      "9 0.000874843099154532\n",
      "9 0.0010344871552661061\n",
      "9 0.0009695073240436614\n",
      "9 0.001028279191814363\n",
      "9 0.0011499124811962247\n",
      "9 0.0010163378901779652\n",
      "9 0.0010871215490624309\n",
      "9 0.000978082069195807\n",
      "9 0.0008216687710955739\n",
      "9 0.0008264438947662711\n",
      "9 0.0010213616769760847\n",
      "9 0.0011621611192822456\n",
      "9 0.0009005789179354906\n",
      "9 0.0011334761511534452\n",
      "9 0.0009545189677737653\n",
      "9 0.0008492354536429048\n",
      "9 0.0008005961426533759\n",
      "9 0.0006885775364935398\n",
      "9 0.0007149112061597407\n",
      "9 0.0008221979951485991\n",
      "9 0.001321514486335218\n",
      "9 0.0008587089832872152\n",
      "10 0.0009683272801339626\n",
      "10 0.001060515409335494\n",
      "10 0.001076195389032364\n",
      "10 0.0007797598373144865\n",
      "10 0.0006972431438043714\n",
      "10 0.000905183027498424\n",
      "10 0.0010547640267759562\n",
      "10 0.000689042906742543\n",
      "10 0.0007180132670328021\n",
      "10 0.0009454775135964155\n",
      "10 0.0010613194899633527\n",
      "10 0.0008441871614195406\n",
      "10 0.0010822226759046316\n",
      "10 0.0009191423887386918\n",
      "10 0.001167416456155479\n",
      "10 0.000765850069001317\n",
      "10 0.0008392283343710005\n",
      "10 0.0011162684531882405\n",
      "10 0.0007528922869823873\n",
      "10 0.0007133092149160802\n",
      "10 0.0013396975118666887\n",
      "10 0.0011711164843291044\n",
      "10 0.0012315836502239108\n",
      "10 0.0010759291471913457\n",
      "10 0.0010116463527083397\n",
      "10 0.0008363862289115787\n",
      "10 0.0011908042943105102\n",
      "10 0.0007763770408928394\n",
      "10 0.0009800498373806477\n",
      "10 0.0009125501965172589\n",
      "10 0.0008280406473204494\n",
      "10 0.0008208422223106027\n",
      "10 0.0007940027862787247\n",
      "10 0.001210809568874538\n",
      "10 0.0008001987589523196\n",
      "10 0.0010305605828762054\n",
      "10 0.0008646773640066385\n",
      "10 0.0008664797060191631\n",
      "10 0.0009370638872496784\n",
      "11 0.0008034665370360017\n",
      "11 0.0007751898956485093\n",
      "11 0.001201875857077539\n",
      "11 0.0009205989772453904\n",
      "11 0.0009922785684466362\n",
      "11 0.0007537687779404223\n",
      "11 0.001026777783408761\n",
      "11 0.00078835483873263\n",
      "11 0.0009614875307306647\n",
      "11 0.001032814965583384\n",
      "11 0.0009660113137215376\n",
      "11 0.0011553114745765924\n",
      "11 0.0010693790391087532\n",
      "11 0.0010381289757788181\n",
      "11 0.0007317937561310828\n",
      "11 0.0007029477856121957\n",
      "11 0.0009127218509092927\n",
      "11 0.0008911460754461586\n",
      "11 0.00090242107398808\n",
      "11 0.0007710944628342986\n",
      "11 0.0009756520157679915\n",
      "11 0.0013980100629851222\n",
      "11 0.0012478894786909223\n",
      "11 0.0010123896645382047\n",
      "11 0.0010626643197610974\n",
      "11 0.0006956233410164714\n",
      "11 0.0012352203484624624\n",
      "11 0.000813717779237777\n",
      "11 0.0007434815634042025\n",
      "11 0.0007168694864958525\n",
      "11 0.001314925029873848\n",
      "11 0.0008898594533093274\n",
      "11 0.0010942226508632302\n",
      "11 0.0007306833285838366\n",
      "11 0.0009481500601395965\n",
      "11 0.0009275490883737803\n",
      "11 0.000982388504780829\n",
      "11 0.0006644052919000387\n",
      "11 0.0006293877959251404\n",
      "12 0.000994336442090571\n",
      "12 0.0011254634009674191\n",
      "12 0.0008571204962208867\n",
      "12 0.0008512231288477778\n",
      "12 0.001127266907133162\n",
      "12 0.0006939220475032926\n",
      "12 0.0009619226912036538\n",
      "12 0.0006968453526496887\n",
      "12 0.0010859468020498753\n",
      "12 0.0009233546443283558\n",
      "12 0.0007428783574141562\n",
      "12 0.0007317193667404354\n",
      "12 0.001003979705274105\n",
      "12 0.0013971410226076841\n",
      "12 0.000860230065882206\n",
      "12 0.0007065937388688326\n",
      "12 0.0006883280584588647\n",
      "12 0.0008743945509195328\n",
      "12 0.0008103121072053909\n",
      "12 0.0011279192985966802\n",
      "12 0.001035799621604383\n",
      "12 0.001117339008487761\n",
      "12 0.000915624899789691\n",
      "12 0.0006933609838597476\n",
      "12 0.0008101818384602666\n",
      "12 0.0011468075681477785\n",
      "12 0.0011151684448122978\n",
      "12 0.0008201993186958134\n",
      "12 0.0007413595449179411\n",
      "12 0.0009548988309688866\n",
      "12 0.000926523469388485\n",
      "12 0.0010722940787672997\n",
      "12 0.0008776731556281447\n",
      "12 0.0011523542925715446\n",
      "12 0.001294942107051611\n",
      "12 0.0010693890508264303\n",
      "12 0.0007089838618412614\n",
      "12 0.0008622520253993571\n",
      "12 0.0008125648600980639\n",
      "13 0.0008640754967927933\n",
      "13 0.0005997861735522747\n",
      "13 0.0009727405849844217\n",
      "13 0.0010259893024340272\n",
      "13 0.0007155443308874965\n",
      "13 0.001263566897250712\n",
      "13 0.0008975230739451945\n",
      "13 0.0009041696321219206\n",
      "13 0.001156943035311997\n",
      "13 0.0009860647842288017\n",
      "13 0.0007278603734448552\n",
      "13 0.0008706507505849004\n",
      "13 0.0006822519353590906\n",
      "13 0.0007769790245220065\n",
      "13 0.0008102812571451068\n",
      "13 0.0007757804123684764\n",
      "13 0.0009115575230680406\n",
      "13 0.0009212538716383278\n",
      "13 0.0010757665149867535\n",
      "13 0.0008269580430351198\n",
      "13 0.0009815192315727472\n",
      "13 0.0013051115674898028\n",
      "13 0.0006544203497469425\n",
      "13 0.0010191458277404308\n",
      "13 0.0009380407864227891\n",
      "13 0.0008151724468916655\n",
      "13 0.0007902749348431826\n",
      "13 0.0012902963208034635\n",
      "13 0.0010801267344504595\n",
      "13 0.0007288272609002888\n",
      "13 0.0008206150960177183\n",
      "13 0.001414846396073699\n",
      "13 0.0012717535719275475\n",
      "13 0.0009031419758684933\n",
      "13 0.0010275761596858501\n",
      "13 0.000936684722546488\n",
      "13 0.0008153887465596199\n",
      "13 0.000914214993827045\n",
      "13 0.0007583798142150044\n",
      "14 0.0006992695271037519\n",
      "14 0.0013411053223535419\n",
      "14 0.0009120631730183959\n",
      "14 0.0012414109660312533\n",
      "14 0.0010532622691243887\n",
      "14 0.0006826254539191723\n",
      "14 0.0008278657332994044\n",
      "14 0.0011694220593199134\n",
      "14 0.0008610302465967834\n",
      "14 0.0007860658224672079\n",
      "14 0.0008973391377367079\n",
      "14 0.0007416823063977063\n",
      "14 0.0009102968615479767\n",
      "14 0.0007197153754532337\n",
      "14 0.0010993907926604152\n",
      "14 0.000849359028507024\n",
      "14 0.000680377590470016\n",
      "14 0.0007990750600583851\n",
      "14 0.0012138066813349724\n",
      "14 0.0007861324120312929\n",
      "14 0.0007778754225000739\n",
      "14 0.0008220722666010261\n",
      "14 0.0012742617400363088\n",
      "14 0.000884751440025866\n",
      "14 0.0008754002046771348\n",
      "14 0.0007549647707492113\n",
      "14 0.001188578549772501\n",
      "14 0.0008248522644862533\n",
      "14 0.0011011462192982435\n",
      "14 0.0009995329892262816\n",
      "14 0.0011139361886307597\n",
      "14 0.001136830891482532\n",
      "14 0.000712679757270962\n",
      "14 0.0008920993423089385\n",
      "14 0.0007439627079293132\n",
      "14 0.0007366410573013127\n",
      "14 0.0008571567595936358\n",
      "14 0.001250048284418881\n",
      "14 0.0010466016829013824\n",
      "15 0.0007597020012326539\n",
      "15 0.0006716276984661818\n",
      "15 0.0007315511466003954\n",
      "15 0.0015389651525765657\n",
      "15 0.0008586742915213108\n",
      "15 0.0011153233936056495\n",
      "15 0.0010250238701701164\n",
      "15 0.000887619738932699\n",
      "15 0.0007421127520501614\n",
      "15 0.0009367992170155048\n",
      "15 0.0008070414187386632\n",
      "15 0.0008611140074208379\n",
      "15 0.0007049854611977935\n",
      "15 0.0007850290276110172\n",
      "15 0.0010068551637232304\n",
      "15 0.0010864376090466976\n",
      "15 0.0008292902493849397\n",
      "15 0.0010746442712843418\n",
      "15 0.0010698377154767513\n",
      "15 0.0008462638361379504\n",
      "15 0.0008194807451218367\n",
      "15 0.0008862597169354558\n",
      "15 0.0007579905213788152\n",
      "15 0.000763630261644721\n",
      "15 0.0009050429216586053\n",
      "15 0.0011724046198651195\n",
      "15 0.0012355523649603128\n",
      "15 0.0006777337985113263\n",
      "15 0.0011959595140069723\n",
      "15 0.0007442714413627982\n",
      "15 0.0009263672400265932\n",
      "15 0.0011339567136019468\n",
      "15 0.0009822013089433312\n",
      "15 0.0007766223861835897\n",
      "15 0.0008411017479375005\n",
      "15 0.0008225084166042507\n",
      "15 0.0009728988516144454\n",
      "15 0.0012831733329221606\n",
      "15 0.0008461528923362494\n",
      "16 0.0007585907005704939\n",
      "16 0.0008080304833129048\n",
      "16 0.000673860777169466\n",
      "16 0.0008610140066593885\n",
      "16 0.0006872320082038641\n",
      "16 0.0007481576758436859\n",
      "16 0.0012558939633890986\n",
      "16 0.000755203771404922\n",
      "16 0.0011366294929757714\n",
      "16 0.0008324026130139828\n",
      "16 0.0010950006544589996\n",
      "16 0.0008799733477644622\n",
      "16 0.001021758303977549\n",
      "16 0.0009074360132217407\n",
      "16 0.0007566709537059069\n",
      "16 0.0007478108163923025\n",
      "16 0.0008782218210399151\n",
      "16 0.0011329331900924444\n",
      "16 0.000820460612885654\n",
      "16 0.0008733575814403594\n",
      "16 0.001263749087229371\n",
      "16 0.0008574294624850154\n",
      "16 0.0012449721107259393\n",
      "16 0.0009640945354476571\n",
      "16 0.0008155808318406343\n",
      "16 0.0007245024316944182\n",
      "16 0.0008327002287842333\n",
      "16 0.001073232269845903\n",
      "16 0.0008517808164469898\n",
      "16 0.0008716387092135847\n",
      "16 0.000987494713626802\n",
      "16 0.0007577945943921804\n",
      "16 0.0009642581571824849\n",
      "16 0.0008794446475803852\n",
      "16 0.0009649394196458161\n",
      "16 0.00118162389844656\n",
      "16 0.0012488799402490258\n",
      "16 0.0007914205198176205\n",
      "16 0.001362612354569137\n",
      "17 0.0011723688803613186\n",
      "17 0.0009161130292341113\n",
      "17 0.0007463272195309401\n",
      "17 0.0008240723400376737\n",
      "17 0.0009916553972288966\n",
      "17 0.0008489665342494845\n",
      "17 0.0009981731418520212\n",
      "17 0.0014786579413339496\n",
      "17 0.0010971988085657358\n",
      "17 0.0012015162501484156\n",
      "17 0.000982901663519442\n",
      "17 0.0008079669787548482\n",
      "17 0.0010503814555704594\n",
      "17 0.0007410546531900764\n",
      "17 0.0010372059186920524\n",
      "17 0.0008633917896077037\n",
      "17 0.0008362190565094352\n",
      "17 0.0009592105634510517\n",
      "17 0.0007874357397668064\n",
      "17 0.0008726816158741713\n",
      "17 0.0009635110618546605\n",
      "17 0.0007951316656544805\n",
      "17 0.0006191374268382788\n",
      "17 0.0012609019177034497\n",
      "17 0.0007325226906687021\n",
      "17 0.000775301712565124\n",
      "17 0.0010658502578735352\n",
      "17 0.0007673827931284904\n",
      "17 0.0010985087137669325\n",
      "17 0.0007503521628677845\n",
      "17 0.0006425772444345057\n",
      "17 0.0010549341095611453\n",
      "17 0.0007928372360765934\n",
      "17 0.0006895377300679684\n",
      "17 0.0011985739693045616\n",
      "17 0.0008817650959827006\n",
      "17 0.0010150818852707744\n",
      "17 0.0008270351099781692\n",
      "17 0.000790590769611299\n",
      "18 0.0006806757883168757\n",
      "18 0.0009141292539425194\n",
      "18 0.0008399721700698137\n",
      "18 0.000728582323063165\n",
      "18 0.0011315030278638005\n",
      "18 0.0009233100572600961\n",
      "18 0.0008973405347205698\n",
      "18 0.0007898303447291255\n",
      "18 0.001119677908718586\n",
      "18 0.0009606362436898053\n",
      "18 0.0009577675373293459\n",
      "18 0.0008192317327484488\n",
      "18 0.001358501147478819\n",
      "18 0.001025359844788909\n",
      "18 0.0009314447524957359\n",
      "18 0.0007935807225294411\n",
      "18 0.0008127653272822499\n",
      "18 0.0007497642654925585\n",
      "18 0.0011760765919461846\n",
      "18 0.0007311197696253657\n",
      "18 0.0010733191156759858\n",
      "18 0.0007758999126963317\n",
      "18 0.0008608434000052512\n",
      "18 0.0009610216366127133\n",
      "18 0.000984512036666274\n",
      "18 0.0008762700599618256\n",
      "18 0.0008249682723544538\n",
      "18 0.001046959776431322\n",
      "18 0.001129849930293858\n",
      "18 0.0007456025923602283\n",
      "18 0.0007506209658458829\n",
      "18 0.0007025548839010298\n",
      "18 0.0008243003394454718\n",
      "18 0.0009261957602575421\n",
      "18 0.0010006983065977693\n",
      "18 0.000994708389043808\n",
      "18 0.0012510085944086313\n",
      "18 0.0008791843429207802\n",
      "18 0.0011640351731330156\n",
      "19 0.0008358883205801249\n",
      "19 0.0009106453508138657\n",
      "19 0.001241999096237123\n",
      "19 0.0010635788785293698\n",
      "19 0.0011683821212500334\n",
      "19 0.0008280694019049406\n",
      "19 0.001050239079631865\n",
      "19 0.000757656991481781\n",
      "19 0.000767888966947794\n",
      "19 0.0008328257827088237\n",
      "19 0.0006928523653186858\n",
      "19 0.0011281928746029735\n",
      "19 0.0007811697432771325\n",
      "19 0.0008478407398797572\n",
      "19 0.0006547943921759725\n",
      "19 0.0010649733012542129\n",
      "19 0.000833979167509824\n",
      "19 0.0009357671951875091\n",
      "19 0.0007875059964135289\n",
      "19 0.0007574851042591035\n",
      "19 0.0007017579046078026\n",
      "19 0.0006767055601812899\n",
      "19 0.0009504866320639849\n",
      "19 0.0008220869349315763\n",
      "19 0.0009751975303515792\n",
      "19 0.0009430930949747562\n",
      "19 0.0009444699389860034\n",
      "19 0.000944338331464678\n",
      "19 0.0011384887620806694\n",
      "19 0.001090992009267211\n",
      "19 0.0009139981120824814\n",
      "19 0.0010154066840186715\n",
      "19 0.0008486710721626878\n",
      "19 0.0010602287948131561\n",
      "19 0.0010048195254057646\n",
      "19 0.0007101384690031409\n",
      "19 0.0012707605492323637\n",
      "19 0.000808633049018681\n",
      "19 0.0013876637676730752\n",
      "20 0.0011337100295349956\n",
      "20 0.0008069407194852829\n",
      "20 0.0007610726752318442\n",
      "20 0.0007836398435756564\n",
      "20 0.0007625842117704451\n",
      "20 0.0008351228898391128\n",
      "20 0.0008390081347897649\n",
      "20 0.0009553072741255164\n",
      "20 0.0009467232739552855\n",
      "20 0.0007614728529006243\n",
      "20 0.0007822162588126957\n",
      "20 0.0009385704761371017\n",
      "20 0.0008358840714208782\n",
      "20 0.000777600216679275\n",
      "20 0.0008323362562805414\n",
      "20 0.0010131667368113995\n",
      "20 0.0008385754190385342\n",
      "20 0.0009752791956998408\n",
      "20 0.0009516074787825346\n",
      "20 0.0007094289176166058\n",
      "20 0.0008716777665540576\n",
      "20 0.0011965722078457475\n",
      "20 0.0011668693041428924\n",
      "20 0.000814662838820368\n",
      "20 0.0010445903753861785\n",
      "20 0.000991358538158238\n",
      "20 0.0012659518979489803\n",
      "20 0.0011487844167277217\n",
      "20 0.0012072366662323475\n",
      "20 0.0009875386022031307\n",
      "20 0.0010390137322247028\n",
      "20 0.0009919429430738091\n",
      "20 0.0008055930957198143\n",
      "20 0.0008002961403690279\n",
      "20 0.0006581064080819488\n",
      "20 0.0011052727932110429\n",
      "20 0.0007857562741264701\n",
      "20 0.0008821194642223418\n",
      "20 0.0008798605995252728\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "for i in range(iterations):\n",
    "    for batch_idx, (batch_X, batch_Y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(batch_X)\n",
    "        loss = criterion(outputs, batch_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(i+1, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1978,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9888, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "net.eval()\n",
    "\n",
    "#testX_tensor.cpu()\n",
    "#net.cpu()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted = net(testX_tensor).detach().cpu().numpy()\n",
    "\n",
    "# 예측값, 레이블 역정규화 (Kaggle 제출을 위해)\n",
    "predicted = inverse_minmax_scaler(predicted, trainY_min, trainY_max)\n",
    "print(predicted.shape)\n",
    "print(type(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1979,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9888, 1)\n",
      "   battery_output\n",
      "0          -0.338\n",
      "1          -0.334\n",
      "2          -0.331\n",
      "3          -0.324\n",
      "4          -0.323\n"
     ]
    }
   ],
   "source": [
    "predicted_df = pd.DataFrame(predicted, columns=[\"battery_output\"])\n",
    "predicted_df = predicted_df.round(3)\n",
    "print(predicted_df.shape)\n",
    "print(predicted_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1980,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9888, 2)\n"
     ]
    }
   ],
   "source": [
    "# \"id\" 컬럼 추가\n",
    "predicted_df[\"id\"] = range(39457, 39457 + len(predicted_df))\n",
    "# \"id\" 컬럼을 첫 번째 컬럼으로 이동\n",
    "predicted_df = predicted_df[[\"id\", \"battery_output\"]]\n",
    "print(predicted_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1981,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame을 CSV 파일로 저장\n",
    "csv_file_path = \"./submission/Prediction.csv\"\n",
    "predicted_df.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
