{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-18T13:53:44.952925Z","iopub.status.busy":"2024-07-18T13:53:44.952497Z","iopub.status.idle":"2024-07-18T14:51:36.141576Z","shell.execute_reply":"2024-07-18T14:51:36.140544Z","shell.execute_reply.started":"2024-07-18T13:53:44.952893Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import torch\n","\n","# 데이터 로드\n","train_df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip', compression='zip')\n","test_df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip', compression='zip')\n","\n","# 데이터 확인\n","train_df.head()\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","# 파라미터 설정\n","max_words = 20000\n","max_len = 100\n","\n","# 토크나이저 정의\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(train_df['comment_text'])\n","\n","# 텍스트를 시퀀스로 변환\n","X_train = tokenizer.texts_to_sequences(train_df['comment_text'])\n","X_test = tokenizer.texts_to_sequences(test_df['comment_text'])\n","\n","# 패딩 적용\n","X_train = pad_sequences(X_train, maxlen=max_len)\n","X_test = pad_sequences(X_test, maxlen=max_len)\n","\n","# 타겟 변수 설정\n","y_train = train_df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ToxicCommentsDataset(Dataset):\n","    def __init__(self, texts, labels=None):\n","        self.texts = texts\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        if self.labels is not None:\n","            label = self.labels[idx]\n","            return torch.tensor(text, dtype=torch.long), torch.tensor(label, dtype=torch.float)\n","        return torch.tensor(text, dtype=torch.long)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch_size = 128\n","\n","train_dataset = ToxicCommentsDataset(X_train, y_train)\n","test_dataset = ToxicCommentsDataset(X_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","class CNNModel(nn.Module):\n","    def __init__(self, vocab_size, embed_size, num_classes):\n","        super(CNNModel, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.conv1 = nn.Conv1d(embed_size, 64, kernel_size=5, stride=1)\n","        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n","        self.fc1 = nn.Linear(64 * ((max_len - 5 + 1) // 2), 64)\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(64, num_classes)\n","    \n","    def forward(self, x):\n","        x = self.embedding(x).permute(0, 2, 1)\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = x.view(x.size(0), -1)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = torch.sigmoid(self.fc2(x))\n","        return x\n","\n","vocab_size = max_words\n","embed_size = 128\n","num_classes = 6\n","\n","model = CNNModel(vocab_size, embed_size, num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 손실 함수와 옵티마이저 정의\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# 학습\n","num_epochs = 5\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    for texts, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(texts)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 예측 수행\n","model.eval()\n","predictions = []\n","\n","with torch.no_grad():\n","    for texts in test_loader:\n","        outputs = model(texts)\n","        predictions.append(outputs.cpu().numpy())\n","\n","predictions = np.vstack(predictions)\n","\n","# 결과 저장\n","submission_df = pd.DataFrame(predictions, columns=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\n","submission_df.insert(0, 'id', test_df['id'])\n","submission_df.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":44219,"sourceId":8076,"sourceType":"competition"}],"dockerImageVersionId":30746,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
